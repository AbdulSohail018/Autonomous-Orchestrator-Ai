name: Python Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]

    steps:
    - uses: actions/checkout@v5

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gcc python3-dev

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov black isort ruff
        pip install -r agent/requirements.txt
        pip install -r kafka/producer/requirements.txt
        # Install minimal versions for testing (without heavy Spark dependencies)
        pip install pandas==2.0.3 pydantic==2.5.3 requests==2.31.0 python-dotenv==1.0.0

    - name: Lint with ruff
      run: |
        ruff check agent ops kafka/producer --output-format=github

    - name: Check formatting with black
      run: |
        black --check agent ops kafka/producer

    - name: Check import sorting with isort
      run: |
        isort --check-only agent ops kafka/producer

    - name: Test with pytest
      run: |
        # Run tests without Spark dependencies
        pytest tests/test_agent.py tests/test_dq.py -v --tb=short --cov=agent --cov=ops
        # Run Spark tests only if PySpark is available
        pytest tests/test_spark_jobs.py -v --tb=short -k "not spark_available" || echo "Skipping Spark tests (PySpark not available)"

    - name: Upload coverage reports to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.10'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10

    - name: Install linting dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black isort ruff

    - name: Run ruff
      run: ruff check agent ops kafka/producer

    - name: Run black
      run: black --check agent ops kafka/producer

    - name: Run isort
      run: isort --check-only agent ops kafka/producer

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10

    - name: Install security scanning tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Run bandit security linter
      run: |
        bandit -r agent ops kafka/producer -f json -o bandit-report.json || true

    - name: Run safety dependency checker
      run: |
        safety check --json --output safety-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  validate-config:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v5

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.10

    - name: Install validation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install jsonschema pyyaml

    - name: Validate JSON configurations
      run: |
        python -c "import json; json.load(open('kafka/schemas/customer_events.avsc'))"
        python -c "import json; json.load(open('dq/expectations/customers_expectation_suite.json'))"
        echo "JSON configurations are valid"

    - name: Validate YAML configurations
      run: |
        python -c "import yaml; yaml.safe_load(open('airflow/include/config.yml'))"
        python -c "import yaml; yaml.safe_load(open('dq/ge_checkpoint.yml'))"
        echo "YAML configurations are valid"

    - name: Validate Docker configurations
      run: |
        # Check docker-compose files for syntax
        docker-compose -f docker-compose.yml config > /dev/null
        docker-compose -f kafka/docker-compose.kafka.yml config > /dev/null
        echo "Docker Compose configurations are valid"

  build-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v5

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build producer image
      run: |
        docker build -f Dockerfile.producer -t test-producer .

    - name: Test producer image
      run: |
        # Quick test that the image can run
        docker run --rm test-producer python3 --version

  integration-test:
    runs-on: ubuntu-latest
    needs: [test, lint, validate-config]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v5

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Create test environment file
      run: |
        cp .env.example .env
        echo "AIRFLOW_UID=50000" >> .env

    - name: Start test services
      run: |
        # Start minimal services for integration test
        docker-compose -f kafka/docker-compose.kafka.yml up -d
        
        # Wait for Kafka to be ready
        timeout 60s bash -c 'until docker-compose -f kafka/docker-compose.kafka.yml exec -T broker kafka-broker-api-versions --bootstrap-server localhost:9092; do sleep 5; done'

    - name: Run integration tests
      run: |
        # Test Kafka connectivity
        docker-compose -f kafka/docker-compose.kafka.yml exec -T broker kafka-topics --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
        docker-compose -f kafka/docker-compose.kafka.yml exec -T broker kafka-topics --list --bootstrap-server localhost:9092 | grep test-topic

    - name: Cleanup test services
      if: always()
      run: |
        docker-compose -f kafka/docker-compose.kafka.yml down -v